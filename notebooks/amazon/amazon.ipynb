{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/Hj7HanKwLSUnJ8UoIftn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/Amazon/blob/main/notebooks/amazon/amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon\n",
        "\n",
        "## Computer Vision\n",
        "\n",
        "- Image Classification\n",
        "- Object Detection\n",
        "- Semantic Segmentation\n",
        "- Instance Segmentation\n",
        "- Image Embedding\n",
        "\n",
        "## Text\n",
        "\n",
        "- Text Classification\n",
        "- Sentence Pair Classification\n",
        "- Question Answering\n",
        "- Named Entity Recognition\n",
        "- Text Summarization\n",
        "- Text Generation\n",
        "- Machine Translation\n",
        "- Text Embedding\n",
        "\n",
        "\n",
        "## Tabular\n",
        "\n",
        "- Tabular Classification (LightGBM & Catboost)\n",
        "- Tabular Classification (XGBoost & Scikit-learn Linear Learner)\n",
        "- Tabular Classification (AutoGluon)\n",
        "- Tabular Classification (TabTransformer)\n",
        "- Tabular Regression (LightGBM & Catboost)\n",
        "- Tabular Regression (XGBoost & Scikit-learn Linear Learner)\n",
        "- Tabular Regression (AutoGluon)\n",
        "- Tabular Regression (TabTransformer)"
      ],
      "metadata": {
        "id": "eSDVecTsglGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Classification"
      ],
      "metadata": {
        "id": "ktbkIiilddp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sagemaker ipywidgets --upgrade --quiet\n",
        "import sagemaker, boto3, json\n",
        "from sagemaker import get_execution_role\n",
        "import IPython\n",
        "import ipywidgets as widgets\n",
        "from sagemaker import image_uris, model_uris, script_uris\n",
        "from sagemaker.model import Model\n",
        "from sagemaker.predictor import Predictor\n",
        "from sagemaker.utils import name_from_base\n",
        "from IPython.core.display import HTML\n",
        "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
        "from sagemaker import hyperparameters\n",
        "from sagemaker.tuner import ContinuousParameter\n",
        "from sagemaker.estimator import Estimator\n",
        "from sagemaker.utils import name_from_base\n",
        "from sagemaker.tuner import HyperparameterTuner\n",
        "from IPython.core.display import HTML"
      ],
      "metadata": {
        "id": "KR3p9qjPddum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aws_role = get_execution_role()\n",
        "aws_region = boto3.Session().region_name\n",
        "sess = sagemaker.Session()"
      ],
      "metadata": {
        "id": "W_mYd4XVZUVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(model_id,\n",
        "    model_version) =\n",
        "     (\n",
        "    \"pytorch-ic-mobilenet-v2\",\n",
        "    \"*\")"
      ],
      "metadata": {
        "id": "q5XTswKlZUYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boto3.client(\"s3\").download_file(\n",
        "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
        ")\n",
        "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
        "    model_list = json.load(json_file)\n",
        "\n",
        "\n",
        "ic_models_all_versions, ic_models = [\n",
        "    model[\"model_id\"] for model in model_list if \"-ic-\" in model[\"model_id\"]\n",
        "], []\n",
        "[ic_models.append(model) for model in ic_models_all_versions if model not in ic_models]\n",
        "\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=ic_models,\n",
        "    value=model_id,\n",
        "    description=\"JumpStart Image Classification Models:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout={\"width\": \"max-content\"},\n",
        ")\n",
        "display(IPython.display.Markdown(\"## Select a JumpStart pre-trained model from the dropdown below\"))\n",
        "display(dropdown)"
      ],
      "metadata": {
        "id": "Rwd6CYSdZUbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "infer_model_id, infer_model_version = dropdown.value, \"*\"\n",
        "\n",
        "endpoint_name = name_from_base(f\"jumpstart-example-{infer_model_id}\")\n",
        "\n",
        "inference_instance_type = \"ml.m5.xlarge\"\n",
        "\n",
        "\n",
        "deploy_image_uri = image_uris.retrieve(\n",
        "    region=None,\n",
        "    framework=None,\n",
        "    image_scope=\"inference\",\n",
        "    model_id=infer_model_id,\n",
        "    model_version=infer_model_version,\n",
        "    instance_type=inference_instance_type,\n",
        ")\n",
        "\n",
        "deploy_source_uri = script_uris.retrieve(\n",
        "    model_id=infer_model_id, model_version=infer_model_version, script_scope=\"inference\"\n",
        ")\n",
        "\n",
        "base_model_uri = model_uris.retrieve(\n",
        "    model_id=infer_model_id, model_version=infer_model_version, model_scope=\"inference\"\n",
        ")\n",
        "\n",
        "    image_uri=deploy_image_uri,\n",
        "    source_dir=deploy_source_uri,\n",
        "    model_data=base_model_uri,\n",
        "    entry_point=\"inference.py\",\n",
        "    role=aws_role,\n",
        "    predictor_cls=Predictor,\n",
        "    name=endpoint_name)\n",
        "\n",
        "base_model_predictor = model.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=inference_instance_type,\n",
        "    endpoint_name=endpoint_name,\n",
        ")"
      ],
      "metadata": {
        "id": "HL-45MmXZUeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
        "key_prefix = \"inference-notebook-assets\"\n",
        "\n",
        "\n",
        "def download_from_s3(images):\n",
        "    for filename, image_key in images.items():\n",
        "        boto3.client(\"s3\").download_file(s3_bucket, f\"{key_prefix}/{image_key}\", filename)\n",
        "\n",
        "\n",
        "images = {\"img1.jpg\": \"cat.jpg\", \"img2.jpg\": \"dog.jpg\"}\n",
        "download_from_s3(images)"
      ],
      "metadata": {
        "id": "UjDTXqEwZUhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_top_k_labels(probabilities, labels, k):\n",
        "    topk_prediction_ids = sorted(\n",
        "        range(len(probabilities)), key=lambda index: probabilities[index], reverse=True\n",
        "    )[:k]\n",
        "    topk_class_labels = \", \".join([labels[id] for id in topk_prediction_ids])\n",
        "    return topk_class_labels\n",
        "\n",
        "\n",
        "for image_filename in images.keys():\n",
        "    with open(image_filename, \"rb\") as file:\n",
        "        img = file.read()\n",
        "    query_response = base_model_predictor.predict(\n",
        "        img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"}\n",
        "    )\n",
        "    model_predictions = json.loads(query_response)\n",
        "    labels, probabilities = model_predictions[\"labels\"], model_predictions[\"probabilities\"]\n",
        "    top5_class_labels = predict_top_k_labels(probabilities, labels, 5)\n",
        "    display(\n",
        "        HTML(\n",
        "            f'<img src={image_filename} alt={image_filename} align=\"left\" style=\"width: 250px;\"/>'\n",
        "            f\"<figcaption>Top-5 predictions: {top5_class_labels} </figcaption>\"\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "dkiXZse9ZUkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the SageMaker endpoint and the attached resources\n",
        "base_model_predictor.delete_model()\n",
        "base_model_predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "BpI0goAlZUof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id, model_version = dropdown.value, \"*\"\n",
        "training_instance_type = \"ml.p3.2xlarge\"\n",
        "\n",
        "# Retrieve the docker image\n",
        "train_image_uri = image_uris.retrieve(\n",
        "    region=None,\n",
        "    framework=None,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    image_scope=\"training\",\n",
        "    instance_type=training_instance_type,\n",
        ")\n",
        "# Retrieve the training script\n",
        "train_source_uri = script_uris.retrieve(\n",
        "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
        ")\n",
        "# Retrieve the pre-trained model tarball to further fine-tune\n",
        "train_model_uri = model_uris.retrieve(\n",
        "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
        ")"
      ],
      "metadata": {
        "id": "fubY1QKhaRpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
        "training_data_prefix = \"training-datasets/tf_flowers/\"\n",
        "\n",
        "training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
        "\n",
        "output_bucket = sess.default_bucket()\n",
        "output_prefix = \"jumpstart-example-ic-training\"\n",
        "\n",
        "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
      ],
      "metadata": {
        "id": "pP6xYrIIaRs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
        "\n",
        "# [Optional] Override default hyperparameters with custom values\n",
        "hyperparameters[\"epochs\"] = \"5\"\n",
        "print(hyperparameters)"
      ],
      "metadata": {
        "id": "o6MoRWmMaRvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_amt = True\n",
        "metric_definitions_per_model = {\n",
        "    \"tensorflow\": {\n",
        "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}],\n",
        "        \"type\": \"Maximize\",\n",
        "    },\n",
        "    \"pytorch\": {\n",
        "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val Acc: ([0-9\\\\.]+)\"}],\n",
        "        \"type\": \"Maximize\"}}\n",
        "\n",
        "\n",
        "hyperparameter_ranges = {\n",
        "    \"adam-learning-rate\": ContinuousParameter(0.0001, 0.1, scaling_type=\"Logarithmic\")\n",
        "}\n",
        "\n",
        "\n",
        "max_jobs = 6\n",
        "\n",
        "max_parallel_jobs = 2"
      ],
      "metadata": {
        "id": "Dl5DtuBjaRyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_job_name = name_from_base(f\"jumpstart-example-{model_id}-transfer-learning\")\n",
        "\n",
        "# Create SageMaker Estimator instance\n",
        "ic_estimator = Estimator(\n",
        "    role=aws_role,\n",
        "    image_uri=train_image_uri,\n",
        "    source_dir=train_source_uri,\n",
        "    model_uri=train_model_uri,\n",
        "    entry_point=\"transfer_learning.py\",\n",
        "    instance_count=1,\n",
        "    instance_type=training_instance_type,\n",
        "    max_run=360000,\n",
        "    hyperparameters=hyperparameters,\n",
        "    output_path=s3_output_location,\n",
        "    base_job_name=training_job_name,\n",
        ")\n",
        "\n",
        "if use_amt:\n",
        "    metric_definitions = next(\n",
        "        value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)\n",
        "    )\n",
        "\n",
        "    hp_tuner = HyperparameterTuner(\n",
        "        ic_estimator,\n",
        "        metric_definitions[\"metrics\"][0][\"Name\"],\n",
        "        hyperparameter_ranges,\n",
        "        metric_definitions[\"metrics\"],\n",
        "        max_jobs=max_jobs,\n",
        "        max_parallel_jobs=max_parallel_jobs,\n",
        "        objective_type=metric_definitions[\"type\"],\n",
        "        base_tuning_job_name=training_job_name,\n",
        "    )\n",
        "\n",
        "    # Launch a SageMaker Tuning job to search for the best hyperparameters\n",
        "    hp_tuner.fit({\"training\": training_dataset_s3_path})\n",
        "else:\n",
        "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
        "    ic_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
      ],
      "metadata": {
        "id": "6hKoFNPkaR02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_instance_type = \"ml.m5.xlarge\"\n",
        "\n",
        "# Retrieve the inference docker container uri\n",
        "deploy_image_uri = image_uris.retrieve(\n",
        "    region=None,\n",
        "    framework=None,\n",
        "    image_scope=\"inference\",\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    instance_type=inference_instance_type,\n",
        ")\n",
        "# Retrieve the inference script uri\n",
        "deploy_source_uri = script_uris.retrieve(\n",
        "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
        ")\n",
        "\n",
        "endpoint_name = name_from_base(f\"jumpstart-example-FT-{model_id}-\")\n",
        "\n",
        "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
        "finetuned_predictor = (hp_tuner if use_amt else ic_estimator).deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=inference_instance_type,\n",
        "    entry_point=\"inference.py\",\n",
        "    image_uri=deploy_image_uri,\n",
        "    source_dir=deploy_source_uri,\n",
        "    endpoint_name=endpoint_name,\n",
        ")"
      ],
      "metadata": {
        "id": "7Ziyrvb9aR3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
        "key_prefix = \"training-datasets/tf_flowers\"\n",
        "\n",
        "\n",
        "def download_from_s3(images):\n",
        "    for filename, image_key in images.items():\n",
        "        boto3.client(\"s3\").download_file(s3_bucket, f\"{key_prefix}/{image_key}\", filename)\n",
        "\n",
        "\n",
        "flower_images = {\n",
        "    \"img1.jpg\": \"roses/10503217854_e66a804309.jpg\",\n",
        "    \"img2.jpg\": \"sunflowers/1008566138_6927679c8a.jpg\",\n",
        "}\n",
        "download_from_s3(flower_images)"
      ],
      "metadata": {
        "id": "CoeSsbxmaR62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_filename in flower_images.keys():\n",
        "    with open(image_filename, \"rb\") as file:\n",
        "        img = file.read()\n",
        "    query_response = finetuned_predictor.predict(\n",
        "        img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"}\n",
        "    )\n",
        "    model_predictions = json.loads(query_response)\n",
        "    predicted_label = model_predictions[\"predicted_label\"]\n",
        "    display(\n",
        "        HTML(\n",
        "            f'<img src={image_filename} alt={image_filename} align=\"left\" style=\"width: 250px;\"/>'\n",
        "            f\"<figcaption>Predicted Label: {predicted_label}</figcaption>\"\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "TJBshUFYaR9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_predictor.delete_model()\n",
        "finetuned_predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "evFiHMNCaSAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the previously trained model path based on the output location where artifacts are stored previously and the training job name.\n",
        "\n",
        "if use_amt:\n",
        "    sage_client = boto3.Session().client(\"sagemaker\")\n",
        "    tuning_job_result = sage_client.describe_hyper_parameter_tuning_job(\n",
        "        HyperParameterTuningJobName=hp_tuner._current_job_name\n",
        "    )\n",
        "    last_training_job_name = tuning_job_result[\"BestTrainingJob\"][\"TrainingJobName\"]\n",
        "else:\n",
        "    last_training_job_name = ic_estimator._current_job_name\n",
        "\n",
        "last_trained_model_path = f\"{s3_output_location}/{last_training_job_name}/output/model.tar.gz\""
      ],
      "metadata": {
        "id": "0H0EY4bKZUr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qTONrIzib5qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incremental_train_output_prefix = \"jumpstart-example-ic-incremental-training\"\n",
        "incremental_s3_output_location = f\"s3://{output_bucket}/{incremental_train_output_prefix}/output\"\n",
        "incremental_training_job_name = name_from_base(f\"jumpstart-example-{model_id}-incremental-training\")\n",
        "incremental_train_estimator = Estimator(\n",
        "    role=aws_role,\n",
        "    image_uri=train_image_uri,\n",
        "    source_dir=train_source_uri,\n",
        "    model_uri=last_trained_model_path,\n",
        "    entry_point=\"transfer_learning.py\",\n",
        "    instance_count=1,\n",
        "    instance_type=training_instance_type,\n",
        "    max_run=360000,\n",
        "    hyperparameters=hyperparameters,\n",
        "    output_path=incremental_s3_output_location,\n",
        "    base_job_name=incremental_training_job_name,\n",
        ")\n",
        "\n",
        "incremental_train_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
      ],
      "metadata": {
        "id": "CqT24amNbF5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object Detection"
      ],
      "metadata": {
        "id": "LFwm5lJQbxLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sagemaker ipywidgets --upgrade --quiet\n",
        "import sagemaker, boto3, json\n",
        "from sagemaker import get_execution_role\n",
        "import IPython\n",
        "import ipywidgets as widgets\n",
        "from sagemaker import image_uris, model_uris, script_uris\n",
        "from sagemaker.model import Model\n",
        "from sagemaker.predictor import Predictor\n",
        "from sagemaker.utils import name_from_base\n",
        "from IPython.core.display import HTML\n",
        "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
        "from sagemaker import hyperparameters\n",
        "from sagemaker.tuner import ContinuousParameter\n",
        "from sagemaker.estimator import Estimator\n",
        "from sagemaker.utils import name_from_base\n",
        "from sagemaker.tuner import HyperparameterTuner\n",
        "from IPython.core.display import HTML"
      ],
      "metadata": {
        "id": "InFhW2oHbF8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aws_role = get_execution_role()\n",
        "aws_region = boto3.Session().region_name\n",
        "sess = sagemaker.Session()"
      ],
      "metadata": {
        "id": "mByGRj7DbF_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    model_id,\n",
        "    model_version,\n",
        ") = (\n",
        "    \"pytorch-ic-mobilenet-v2\",\n",
        "    \"*\",\n",
        ")"
      ],
      "metadata": {
        "id": "xYVROa5RbGCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download JumpStart model_manifest file.\n",
        "boto3.client(\"s3\").download_file(\n",
        "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
        ")\n",
        "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
        "    model_list = json.load(json_file)\n",
        "\n",
        "# filter-out all the Image Classification models from the manifest list.\n",
        "ic_models_all_versions, ic_models = [\n",
        "    model[\"model_id\"] for model in model_list if \"-ic-\" in model[\"model_id\"]\n",
        "], []\n",
        "[ic_models.append(model) for model in ic_models_all_versions if model not in ic_models]\n",
        "\n",
        "# display the model-ids in a dropdown, for user to select a model.\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=ic_models,\n",
        "    value=model_id,\n",
        "    description=\"JumpStart Image Classification Models:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout={\"width\": \"max-content\"},\n",
        ")\n",
        "display(IPython.display.Markdown(\"## Select a JumpStart pre-trained model from the dropdown below\"))\n",
        "display(dropdown)"
      ],
      "metadata": {
        "id": "1fINA0jDbGFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_model_id, infer_model_version = dropdown.value, \"*\"\n",
        "\n",
        "endpoint_name = name_from_base(f\"jumpstart-example-{infer_model_id}\")\n",
        "\n",
        "inference_instance_type = \"ml.m5.xlarge\"\n",
        "\n",
        "# Retrieve the inference docker container uri.\n",
        "deploy_image_uri = image_uris.retrieve(\n",
        "    region=None,\n",
        "    framework=None,\n",
        "    image_scope=\"inference\",\n",
        "    model_id=infer_model_id,\n",
        "    model_version=infer_model_version,\n",
        "    instance_type=inference_instance_type,\n",
        ")\n",
        "# Retrieve the inference script uri.\n",
        "deploy_source_uri = script_uris.retrieve(\n",
        "    model_id=infer_model_id, model_version=infer_model_version, script_scope=\"inference\"\n",
        ")\n",
        "# Retrieve the base model uri.\n",
        "base_model_uri = model_uris.retrieve(\n",
        "    model_id=infer_model_id, model_version=infer_model_version, model_scope=\"inference\"\n",
        ")\n",
        "# Create the SageMaker model instance. Note that we need to pass Predictor class when we deploy model through Model class,\n",
        "# for being able to run inference through the sagemaker API.\n",
        "model = Model(\n",
        "    image_uri=deploy_image_uri,\n",
        "    source_dir=deploy_source_uri,\n",
        "    model_data=base_model_uri,\n",
        "    entry_point=\"inference.py\",\n",
        "    role=aws_role,\n",
        "    predictor_cls=Predictor,\n",
        "    name=endpoint_name,\n",
        ")\n",
        "# deploy the Model.\n",
        "base_model_predictor = model.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=inference_instance_type,\n",
        "    endpoint_name=endpoint_name,\n",
        ")"
      ],
      "metadata": {
        "id": "KtyfWh17bGIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
        "key_prefix = \"inference-notebook-assets\"\n",
        "\n",
        "\n",
        "def download_from_s3(images):\n",
        "    for filename, image_key in images.items():\n",
        "        boto3.client(\"s3\").download_file(s3_bucket, f\"{key_prefix}/{image_key}\", filename)\n",
        "\n",
        "\n",
        "images = {\"img1.jpg\": \"cat.jpg\", \"img2.jpg\": \"dog.jpg\"}\n",
        "download_from_s3(images)"
      ],
      "metadata": {
        "id": "-bTTMMy8bGLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_top_k_labels(probabilities, labels, k):\n",
        "    topk_prediction_ids = sorted(\n",
        "        range(len(probabilities)), key=lambda index: probabilities[index], reverse=True\n",
        "    )[:k]\n",
        "    topk_class_labels = \", \".join([labels[id] for id in topk_prediction_ids])\n",
        "    return topk_class_labels\n",
        "\n",
        "\n",
        "for image_filename in images.keys():\n",
        "    with open(image_filename, \"rb\") as file:\n",
        "        img = file.read()\n",
        "    query_response = base_model_predictor.predict(\n",
        "        img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"}\n",
        "    )\n",
        "    model_predictions = json.loads(query_response)\n",
        "    labels, probabilities = model_predictions[\"labels\"], model_predictions[\"probabilities\"]\n",
        "    top5_class_labels = predict_top_k_labels(probabilities, labels, 5)\n",
        "    display(\n",
        "        HTML(\n",
        "            f'<img src={image_filename} alt={image_filename} align=\"left\" style=\"width: 250px;\"/>'\n",
        "            f\"<figcaption>Top-5 predictions: {top5_class_labels} </figcaption>\"\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "by-fdPEkdLnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_predictor.delete_model()\n",
        "base_model_predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "qEK1T1T3dLqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id, model_version = dropdown.value, \"*\"\n",
        "training_instance_type = \"ml.p3.2xlarge\"\n",
        "\n",
        "# Retrieve the docker image\n",
        "train_image_uri = image_uris.retrieve(\n",
        "    region=None,\n",
        "    framework=None,\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    image_scope=\"training\",\n",
        "    instance_type=training_instance_type,\n",
        ")\n",
        "# Retrieve the training script\n",
        "train_source_uri = script_uris.retrieve(\n",
        "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
        ")\n",
        "# Retrieve the pre-trained model tarball to further fine-tune\n",
        "train_model_uri = model_uris.retrieve(\n",
        "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
        ")"
      ],
      "metadata": {
        "id": "R1feVajgdLtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
        "training_data_prefix = \"training-datasets/tf_flowers/\"\n",
        "\n",
        "training_dataset_s3_path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
        "\n",
        "output_bucket = sess.default_bucket()\n",
        "output_prefix = \"jumpstart-example-ic-training\"\n",
        "\n",
        "s3_output_location = f\"s3://{output_bucket}/{output_prefix}/output\""
      ],
      "metadata": {
        "id": "CsXKc3gedLwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the default hyper-parameters for fine-tuning the model\n",
        "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
        "\n",
        "# [Optional] Override default hyperparameters with custom values\n",
        "hyperparameters[\"epochs\"] = \"5\"\n",
        "print(hyperparameters)"
      ],
      "metadata": {
        "id": "C0WEUM_vdLzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use AMT for tuning and selecting the best model\n",
        "use_amt = True\n",
        "\n",
        "# Define objective metric per framework, based on which the best model will be selected.\n",
        "metric_definitions_per_model = {\n",
        "    \"tensorflow\": {\n",
        "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}],\n",
        "        \"type\": \"Maximize\",\n",
        "    },\n",
        "    \"pytorch\": {\n",
        "        \"metrics\": [{\"Name\": \"val_accuracy\", \"Regex\": \"val Acc: ([0-9\\\\.]+)\"}],\n",
        "        \"type\": \"Maximize\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# You can select from the hyperparameters supported by the model, and configure ranges of values to be searched for training the optimal model.(https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html)\n",
        "hyperparameter_ranges = {\n",
        "    \"adam-learning-rate\": ContinuousParameter(0.0001, 0.1, scaling_type=\"Logarithmic\")\n",
        "}\n",
        "\n",
        "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
        "max_jobs = 6\n",
        "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
        "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
        "max_parallel_jobs = 2"
      ],
      "metadata": {
        "id": "B38CwruMdL2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_job_name = name_from_base(f\"jumpstart-example-{model_id}-transfer-learning\")\n",
        "\n",
        "# Create SageMaker Estimator instance\n",
        "ic_estimator = Estimator(\n",
        "    role=aws_role,\n",
        "    image_uri=train_image_uri,\n",
        "    source_dir=train_source_uri,\n",
        "    model_uri=train_model_uri,\n",
        "    entry_point=\"transfer_learning.py\",\n",
        "    instance_count=1,\n",
        "    instance_type=training_instance_type,\n",
        "    max_run=360000,\n",
        "    hyperparameters=hyperparameters,\n",
        "    output_path=s3_output_location,\n",
        "    base_job_name=training_job_name,\n",
        ")\n",
        "\n",
        "if use_amt:\n",
        "    metric_definitions = next(\n",
        "        value for key, value in metric_definitions_per_model.items() if model_id.startswith(key)\n",
        "    )\n",
        "\n",
        "    hp_tuner = HyperparameterTuner(\n",
        "        ic_estimator,\n",
        "        metric_definitions[\"metrics\"][0][\"Name\"],\n",
        "        hyperparameter_ranges,\n",
        "        metric_definitions[\"metrics\"],\n",
        "        max_jobs=max_jobs,\n",
        "        max_parallel_jobs=max_parallel_jobs,\n",
        "        objective_type=metric_definitions[\"type\"],\n",
        "        base_tuning_job_name=training_job_name,\n",
        "    )\n",
        "\n",
        "    # Launch a SageMaker Tuning job to search for the best hyperparameters\n",
        "    hp_tuner.fit({\"training\": training_dataset_s3_path})\n",
        "else:\n",
        "    # Launch a SageMaker Training job by passing s3 path of the training data\n",
        "    ic_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
      ],
      "metadata": {
        "id": "47vqw1azdL6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_instance_type = \"ml.m5.xlarge\"\n",
        "\n",
        "# Retrieve the inference docker container uri\n",
        "deploy_image_uri = image_uris.retrieve(\n",
        "    region=None,\n",
        "    framework=None,\n",
        "    image_scope=\"inference\",\n",
        "    model_id=model_id,\n",
        "    model_version=model_version,\n",
        "    instance_type=inference_instance_type,\n",
        ")\n",
        "# Retrieve the inference script uri\n",
        "deploy_source_uri = script_uris.retrieve(\n",
        "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
        ")\n",
        "\n",
        "endpoint_name = name_from_base(f\"jumpstart-example-FT-{model_id}-\")\n",
        "\n",
        "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
        "finetuned_predictor = (hp_tuner if use_amt else ic_estimator).deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=inference_instance_type,\n",
        "    entry_point=\"inference.py\",\n",
        "    image_uri=deploy_image_uri,\n",
        "    source_dir=deploy_source_uri,\n",
        "    endpoint_name=endpoint_name,\n",
        ")"
      ],
      "metadata": {
        "id": "Jg9lz7G0dL9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
        "key_prefix = \"training-datasets/tf_flowers\"\n",
        "\n",
        "\n",
        "def download_from_s3(images):\n",
        "    for filename, image_key in images.items():\n",
        "        boto3.client(\"s3\").download_file(s3_bucket, f\"{key_prefix}/{image_key}\", filename)\n",
        "\n",
        "\n",
        "flower_images = {\n",
        "    \"img1.jpg\": \"roses/10503217854_e66a804309.jpg\",\n",
        "    \"img2.jpg\": \"sunflowers/1008566138_6927679c8a.jpg\",\n",
        "}\n",
        "download_from_s3(flower_images)"
      ],
      "metadata": {
        "id": "6ElUekqidMAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_filename in flower_images.keys():\n",
        "    with open(image_filename, \"rb\") as file:\n",
        "        img = file.read()\n",
        "    query_response = finetuned_predictor.predict(\n",
        "        img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"}\n",
        "    )\n",
        "    model_predictions = json.loads(query_response)\n",
        "    predicted_label = model_predictions[\"predicted_label\"]\n",
        "    display(\n",
        "        HTML(\n",
        "            f'<img src={image_filename} alt={image_filename} align=\"left\" style=\"width: 250px;\"/>'\n",
        "            f\"<figcaption>Predicted Label: {predicted_label}</figcaption>\"\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "V7Vrr4AOdMDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the SageMaker endpoint and the attached resources\n",
        "finetuned_predictor.delete_model()\n",
        "finetuned_predictor.delete_endpoint()"
      ],
      "metadata": {
        "id": "0ABtPeIbdMGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the previously trained model path based on the output location where artifacts are stored previously and the training job name.\n",
        "\n",
        "if use_amt:  # If using amt, select the model for the best training job.\n",
        "    sage_client = boto3.Session().client(\"sagemaker\")\n",
        "    tuning_job_result = sage_client.describe_hyper_parameter_tuning_job(\n",
        "        HyperParameterTuningJobName=hp_tuner._current_job_name\n",
        "    )\n",
        "    last_training_job_name = tuning_job_result[\"BestTrainingJob\"][\"TrainingJobName\"]\n",
        "else:\n",
        "    last_training_job_name = ic_estimator._current_job_name\n",
        "\n",
        "last_trained_model_path = f\"{s3_output_location}/{last_training_job_name}/output/model.tar.gz\""
      ],
      "metadata": {
        "id": "Jfo14nyjbGO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incremental_train_output_prefix = \"jumpstart-example-ic-incremental-training\"\n",
        "\n",
        "incremental_s3_output_location = f\"s3://{output_bucket}/{incremental_train_output_prefix}/output\"\n",
        "\n",
        "incremental_training_job_name = name_from_base(f\"jumpstart-example-{model_id}-incremental-training\")\n",
        "\n",
        "incremental_train_estimator = Estimator(\n",
        "    role=aws_role,\n",
        "    image_uri=train_image_uri,\n",
        "    source_dir=train_source_uri,\n",
        "    model_uri=last_trained_model_path,\n",
        "    entry_point=\"transfer_learning.py\",\n",
        "    instance_count=1,\n",
        "    instance_type=training_instance_type,\n",
        "    max_run=360000,\n",
        "    hyperparameters=hyperparameters,\n",
        "    output_path=incremental_s3_output_location,\n",
        "    base_job_name=incremental_training_job_name,\n",
        ")\n",
        "\n",
        "incremental_train_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
      ],
      "metadata": {
        "id": "dnH6bICWd6JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWoR7pe-d6MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u7NNWtCPd6Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sR1htLe6d6Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrrj_WERd6UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q93PCByid6XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rk6Achhyd6Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QxSemq1tZUvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}