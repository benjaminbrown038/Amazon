{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/NW7MGJm9NHdhB5H/emy9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/Amazon/blob/main/notebooks/amazon/amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sagemaker\n",
        "\n",
        "- Hugging Face\n",
        "- PyTorch\n",
        "- Tensorflow"
      ],
      "metadata": {
        "id": "eSDVecTsglGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sagemaker"
      ],
      "metadata": {
        "id": "K_yAr6Q65xjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "KVKF-sk0glSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install sagemaker\n",
        "import logging\n",
        "import time\n",
        "\n",
        "import boto3\n",
        "\n",
        "import sagemaker\n",
        "from sagemaker.xgboost import XGBoost\n",
        "from sagemaker.experiments.run import Run\n",
        "from sagemaker.analytics import ExperimentAnalytics"
      ],
      "metadata": {
        "id": "UUeZGmrrglcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Role"
      ],
      "metadata": {
        "id": "YpTHksX2gljT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = sagemaker.get_execution_role()\n",
        "role"
      ],
      "metadata": {
        "id": "arqDqFHVuc3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Region"
      ],
      "metadata": {
        "id": "NJR50bDe3i9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region = boto3.Session().region_name\n",
        "region"
      ],
      "metadata": {
        "id": "qHyt9QQCglx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Session"
      ],
      "metadata": {
        "id": "RjtF6t_Y3j_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sagemaker_session = sagemaker.Session()\n",
        "sagemaker_session"
      ],
      "metadata": {
        "id": "wDJCHS6GumP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bucket"
      ],
      "metadata": {
        "id": "whuVFEhn3nuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bucket_name = sagemaker_session.default_bucket()\n",
        "bucket_name"
      ],
      "metadata": {
        "id": "IU-oy3UUgmFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iiQtXyP64Mpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"end-to-end-ml\""
      ],
      "metadata": {
        "id": "LsyYymx7gmPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face"
      ],
      "metadata": {
        "id": "M8JM_CVc4Pkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "O0CgpIxE6GFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sagemaker --upgrade\n",
        "import sagemaker\n",
        "from sagemaker.huggingface import HuggingFace, TrainingCompilerConfig\n",
        "import sagemaker\n",
        "import boto3\n",
        "import transformers\n",
        "import datasets\n",
        "import argparse\n",
        "import os\n",
        "from sagemaker.huggingface import HuggingFace\n",
        "from sagemaker.s3 import S3Downloader"
      ],
      "metadata": {
        "id": "VDOzkIwa6VCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7XLP6RjvXvUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = sagemaker.Session()\n",
        "role = sagemaker.get_execution_role()\n",
        "iam_client = boto3.client('iam')\n",
        "role = iam_client.get_role(RoleName='role-name-of-your-iam-role-with-right-permissions')['Role']['Arn']\n",
        "sess = sagemaker.Session()"
      ],
      "metadata": {
        "id": "ybr8QknGXXlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J5ImmIk5Xu00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # hyperparameters sent by the client are passed as command-line arguments to the script\n",
        "    parser.add_argument(\"--epochs\", type=int, default=3)\n",
        "    parser.add_argument(\"--per_device_train_batch_size\", type=int, default=32)\n",
        "    parser.add_argument(\"--model_name_or_path\", type=str)\n",
        "\n",
        "    # data, model, and output directories\n",
        "    parser.add_argument(\"--model-dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n",
        "    parser.add_argument(\"--training_dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
        "    parser.add_argument(\"--test_dir\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])"
      ],
      "metadata": {
        "id": "WyM-fTNjXXob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EQ9G4F7RXx4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters={'epochs': 1,\n",
        "                 'per_device_train_batch_size': 32,\n",
        "                 'model_name_or_path': 'distilbert-base-uncased'}"
      ],
      "metadata": {
        "id": "lng9UpW8XpXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_GisCiCQXyak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(\n",
        "        entry_point='train.py',\n",
        "        source_dir='./scripts',\n",
        "        instance_type='ml.p3.2xlarge',\n",
        "        instance_count=1,\n",
        "        role=role,\n",
        "        transformers_version='4.26',\n",
        "        pytorch_version='1.13',\n",
        "        py_version='py39',\n",
        "        hyperparameters = hyperparameters)"
      ],
      "metadata": {
        "id": "EyONKhm8X0u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aWj4moMWX2kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator.fit(\n",
        "  {'train': 's3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/train',\n",
        "   'test': 's3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/test'})"
      ],
      "metadata": {
        "id": "scz5Bz7fXfUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EKDkbDYMX8rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/opt/conda/bin/python train.py --epochs 1 --model_name_or_path distilbert-base-uncased --per_device_train_batch_size 32"
      ],
      "metadata": {
        "id": "L2Jm40wVXfYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zdxdm5d9YHro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "S3Downloader.download(\n",
        "    s3_uri=huggingface_estimator.model_data,\n",
        "    local_path='.',\n",
        "    sagemaker_session=sess)"
      ],
      "metadata": {
        "id": "oReasakTXfdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dqdyPfWMYLy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}"
      ],
      "metadata": {
        "id": "cjtokviOXfgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OuOFpQnSYRwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(\n",
        "        entry_point='train.py',\n",
        "        source_dir='./scripts',\n",
        "        instance_type='ml.p3dn.24xlarge',\n",
        "        instance_count=2,\n",
        "        role=role,\n",
        "        transformers_version='4.26.0',\n",
        "        pytorch_version='1.13.1',\n",
        "        py_version='py39',\n",
        "        hyperparameters = hyperparameters,\n",
        "        distribution = distribution)"
      ],
      "metadata": {
        "id": "JAgh55UOYJ_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C3xbPeprYTjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mpi_options = {\n",
        "    \"enabled\" : True,\n",
        "    \"processes_per_host\" : 8}"
      ],
      "metadata": {
        "id": "EY26o46mYKCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KTftdiToYa7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smp_options = {\n",
        "    \"enabled\":True,\n",
        "    \"parameters\": {\n",
        "        \"microbatches\": 4,\n",
        "        \"placement_strategy\": \"spread\",\n",
        "        \"pipeline\": \"interleaved\",\n",
        "        \"optimize\": \"speed\",\n",
        "        \"partitions\": 4,\n",
        "        \"ddp\": True,\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "CSmw5miOYKFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6W6HyPmGYeQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distribution={\n",
        "    \"smdistributed\": {\"modelparallel\": smp_options},\n",
        "    \"mpi\": mpi_options}"
      ],
      "metadata": {
        "id": "-PCefXWfYKId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TdqDU_A8Yg5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(\n",
        "        entry_point='train.py',\n",
        "        source_dir='./scripts',\n",
        "        instance_type='ml.p3dn.24xlarge',\n",
        "        instance_count=2,\n",
        "        role=role,\n",
        "        transformers_version='4.26.0',\n",
        "        pytorch_version='1.13.1',\n",
        "        py_version='py39',\n",
        "        hyperparameters = hyperparameters,\n",
        "        distribution = distribution\n",
        ")"
      ],
      "metadata": {
        "id": "n0oTTeXrYKLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o5ASWiSiYmvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters={'epochs': 1,\n",
        "                 'train_batch_size': 32,\n",
        "                 'model_name':'distilbert-base-uncased',\n",
        "                 'output_dir':'/opt/ml/checkpoints'}"
      ],
      "metadata": {
        "id": "kf8_di0iYKOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DbTWQNQIYrtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(\n",
        "        entry_point='train.py',\n",
        "        source_dir='./scripts',\n",
        "        instance_type='ml.p3.2xlarge',\n",
        "        instance_count=1,\n",
        "\t      checkpoint_s3_uri=f's3://{sess.default_bucket()}/checkpoints'\n",
        "        use_spot_instances=True,\n",
        "        max_wait=3600,\n",
        "        max_run=1000,\n",
        "        role=role,\n",
        "        transformers_version='4.26',\n",
        "        pytorch_version='1.13',\n",
        "        py_version='py39',\n",
        "        hyperparameters = hyperparameters)"
      ],
      "metadata": {
        "id": "bEVvlAOzYKQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_ogdJj7RcFxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.4.2'}"
      ],
      "metadata": {
        "id": "tkCXlWHRYKTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5A9P62_8cFZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(\n",
        "        entry_point='run_glue.py',\n",
        "        source_dir='./examples/pytorch/text-classification',\n",
        "        git_config=git_config,\n",
        "        instance_type='ml.p3.2xlarge',\n",
        "        instance_count=1,\n",
        "        role=role,\n",
        "        transformers_version='4.26',\n",
        "        pytorch_version='1.13',\n",
        "        py_version='py39',\n",
        "        hyperparameters=hyperparameters\n",
        ")"
      ],
      "metadata": {
        "id": "UptX1RgXXXrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "psDKz79AcExG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_definitions = [\n",
        "    {\"Name\": \"train_runtime\", \"Regex\": \"train_runtime.*=\\D*(.*?)$\"},\n",
        "    {\"Name\": \"eval_accuracy\", \"Regex\": \"eval_accuracy.*=\\D*(.*?)$\"},\n",
        "    {\"Name\": \"eval_loss\", \"Regex\": \"eval_loss.*=\\D*(.*?)$\"},\n",
        "]"
      ],
      "metadata": {
        "id": "o-HjxL60ZCDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lsi_ycWrcESI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator = HuggingFace(\n",
        "        entry_point='train.py',\n",
        "        source_dir='./scripts',\n",
        "        instance_type='ml.p3.2xlarge',\n",
        "        instance_count=1,\n",
        "        role=role,\n",
        "        transformers_version='4.26',\n",
        "        pytorch_version='1.13',\n",
        "        py_version='py39',\n",
        "        metric_definitions=metric_definitions,\n",
        "        hyperparameters = hyperparameters)"
      ],
      "metadata": {
        "id": "L1VZ8L0nZD7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PzTDkO7RcDyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_estimator=HuggingFace(\n",
        "    compiler_config=TrainingCompilerConfig())"
      ],
      "metadata": {
        "id": "DqDDKrD86GKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch\n",
        "### Use PyTorch with the SageMaker Python SDK\n",
        "\n",
        "- Train\n",
        "\n",
        "- Deploy"
      ],
      "metadata": {
        "id": "-nq2Oc6l50Iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oa-1a4QYbwim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "if __name__ =='__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
        "    parser.add_argument('--epochs', type=int, default=50)\n",
        "    parser.add_argument('--batch-size', type=int, default=64)\n",
        "    parser.add_argument('--learning-rate', type=float, default=0.05)\n",
        "    parser.add_argument('--use-cuda', type=bool, default=False)\n",
        "\n",
        "    # Data, model, and output directories\n",
        "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
        "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
        "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
        "    parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    # ... load from args.train and args.test, train a model, write model to args.model_dir."
      ],
      "metadata": {
        "id": "zU778pcgbwqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3Ux-3ATabwwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "\n",
        "if __name__=='__main__':\n",
        "    # default to the value in environment variable `SM_MODEL_DIR`. Using args makes the script more portable.\n",
        "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    # ... train `model`, then save it to `model_dir`\n",
        "    with open(os.path.join(args.model_dir, 'model.pth'), 'wb') as f:\n",
        "        torch.save(model.state_dict(), f)"
      ],
      "metadata": {
        "id": "4T_PCDsDbw1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lF3InLa1bw6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# ... train `model`, then save it to `model_dir`\n",
        "model_dir = os.path.join(model_dir, \"model.pt\")\n",
        "torch.jit.save(model, model_dir)"
      ],
      "metadata": {
        "id": "yowfABH-bw_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KN0m73I7bxEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_estimator = PyTorch('pytorch-train.py',\n",
        "                            instance_type='ml.p3.2xlarge',\n",
        "                            instance_count=1,\n",
        "                            framework_version='1.8.0',\n",
        "                            py_version='py3',\n",
        "                            hyperparameters = {'epochs': 20, 'batch-size': 64, 'learning-rate': 0.1})\n",
        "pytorch_estimator.fit({'train': 's3://my-data-bucket/path/to/my/training/data',\n",
        "                       'test': 's3://my-data-bucket/path/to/my/test/data'})"
      ],
      "metadata": {
        "id": "u2_w-o64bxJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9o26f_KebxOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{'train':'s3://my-bucket/my-training-data',\n",
        " 'eval':'s3://my-bucket/my-evaluation-data'}"
      ],
      "metadata": {
        "id": "yK1dMj-UbxTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ntNB3cnKbxXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributed as dist\n",
        "\n",
        "if args.distributed:\n",
        "    # Initialize the distributed environment.\n",
        "    world_size = len(args.hosts)\n",
        "    os.environ['WORLD_SIZE'] = str(world_size)\n",
        "    host_rank = args.hosts.index(args.current_host)\n",
        "    dist.init_process_group(backend=args.backend, rank=host_rank)"
      ],
      "metadata": {
        "id": "66BVK-bBbxc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2FFbsnxXbxhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.pytorch import PyTorch\n",
        "\n",
        "pt_estimator = PyTorch(\n",
        "    entry_point=\"train_ptddp.py\",\n",
        "    role=\"SageMakerRole\",\n",
        "    framework_version=\"1.12.0\",\n",
        "    py_version=\"py38\",\n",
        "    instance_count=2,\n",
        "    instance_type=\"ml.p4d.24xlarge\",\n",
        "    distribution={\n",
        "        \"pytorchddp\": {\n",
        "            \"enabled\": True\n",
        "        }\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "KdFKTTdJbyTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hou4a3sAfhtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.pytorch import PyTorch\n",
        "\n",
        "pt_estimator = PyTorch(\n",
        "    entry_point=\"train_ptddp.py\",\n",
        "    role=\"SageMakerRole\",\n",
        "    framework_version=\"1.13.1\",\n",
        "    py_version=\"py38\",\n",
        "    instance_count=2,\n",
        "    instance_type=\"ml.p4d.24xlarge\",\n",
        "    distribution={\n",
        "        \"torch_distributed\": {\n",
        "            \"enabled\": True\n",
        "        }\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "YFUD-PRzfhyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1J28-6kufiC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributed as dist\n",
        "\n",
        "dist.init_process_group('xla')"
      ],
      "metadata": {
        "id": "KFhxeprffiH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A6RObSvUfiM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.pytorch import PyTorch\n",
        "\n",
        "pt_estimator = PyTorch(\n",
        "    entry_point=\"train_torch_distributed.py\",\n",
        "    role=\"SageMakerRole\",\n",
        "    framework_version=\"1.11.0\",\n",
        "    py_version=\"py38\",\n",
        "    instance_count=1,\n",
        "    instance_type=\"ml.trn1.2xlarge\",\n",
        "    distribution={\n",
        "        \"torch_distributed\": {\n",
        "            \"enabled\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "pt_estimator.fit(\"s3://bucket/path/to/training/data\")"
      ],
      "metadata": {
        "id": "Dwu_FiFIfiR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hUIfw3CgfiWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.pytorch import PyTorch\n",
        "\n",
        "pt_estimator = PyTorch(\n",
        "    entry_point=\"train_torch_distributed.py\",\n",
        "    role=\"SageMakerRole\",\n",
        "    framework_version=\"1.11.0\",\n",
        "    py_version=\"py38\",\n",
        "    instance_count=2,\n",
        "    instance_type=\"ml.trn1.32xlarge\",\n",
        "    distribution={\n",
        "        \"torch_distributed\": {\n",
        "            \"enabled\": True\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "pt_estimator.fit(\"s3://bucket/path/to/training/data\")"
      ],
      "metadata": {
        "id": "CIl8PIk_fibh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d8zyiW8ifiqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train my estimator\n",
        "pytorch_estimator = PyTorch(entry_point='train_and_deploy.py',\n",
        "                            instance_type='ml.p3.2xlarge',\n",
        "                            instance_count=1,\n",
        "                            framework_version='1.8.0',\n",
        "                            py_version='py3')\n",
        "pytorch_estimator.fit('s3://my_bucket/my_training_data/')\n",
        "\n",
        "# Deploy my estimator to a SageMaker Endpoint and get a Predictor\n",
        "predictor = pytorch_estimator.deploy(instance_type='ml.m4.xlarge',\n",
        "                                     initial_instance_count=1)\n",
        "\n",
        "# `data` is a NumPy array or a Python list.\n",
        "# `response` is a NumPy array.\n",
        "response = predictor.predict(data)"
      ],
      "metadata": {
        "id": "VHFWV0bBfiuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zzjnd1PUfi0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = pytorch_estimator.deploy(instance_type='ml.m4.xlarge',\n",
        "                                     initial_instance_count=1,\n",
        "                                     accelerator_type='ml.eia2.medium')"
      ],
      "metadata": {
        "id": "i3ZX0gG-fi4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LjIaB6LqbyYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fn(model_dir, context)"
      ],
      "metadata": {
        "id": "6G8JN94ZbycX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UXPrfimyfxcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "def model_fn(model_dir, context):\n",
        "    model = Your_Model()\n",
        "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
        "        model.load_state_dict(torch.load(f))\n",
        "    return model"
      ],
      "metadata": {
        "id": "6Ko8HtfofxjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uqd8omLYfxqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def model_fn(model_dir):\n",
        "    model = torch.jit.load('model.pth', map_location=torch.device('cpu'))\n",
        "    if torch.__version__ == '1.5.1':\n",
        "        import torcheia\n",
        "        model = model.eval()\n",
        "        # attach_eia() is introduced in PyTorch Elastic Inference 1.5.1,\n",
        "        model = torcheia.jit.attach_eia(model, 0)\n",
        "    return model"
      ],
      "metadata": {
        "id": "qIHSxAJ9fxzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ixQAqz-bfx5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deserialize the Invoke request body into an object we can perform prediction on\n",
        "input_object = input_fn(request_body, request_content_type, context)\n",
        "\n",
        "# Perform prediction on the deserialized object, with the loaded model\n",
        "prediction = predict_fn(input_object, model, context)\n",
        "\n",
        "# Serialize the prediction result into the desired response content type\n",
        "output = output_fn(prediction, response_content_type, context)"
      ],
      "metadata": {
        "id": "piZDyR7-fyAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Up05HeOafyFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn(request_body, request_content_type, context)"
      ],
      "metadata": {
        "id": "7kJ-IYiRfyLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CG6PhTjrfyQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from six import BytesIO\n",
        "\n",
        "def input_fn(request_body, request_content_type):\n",
        "    \"\"\"An input_fn that loads a pickled tensor\"\"\"\n",
        "    if request_content_type == 'application/python-pickle':\n",
        "        return torch.load(BytesIO(request_body))\n",
        "    else:\n",
        "        # Handle other content-types here or raise an Exception\n",
        "        # if the content type is not supported.\n",
        "        pass"
      ],
      "metadata": {
        "id": "f0H5IF4PfyWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FhjIWlepfydx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_fn(input_object, model, context)"
      ],
      "metadata": {
        "id": "Ue41sWIhfyjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ByZiP5WHfyqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def predict_fn(input_data, model):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        return model(input_data.to(device))"
      ],
      "metadata": {
        "id": "urcRCEAPfyvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9M3A3cAaf-D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def predict_fn(input_data, model, context):\n",
        "    device = torch.device(\"cuda:\" + str(context.system_properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        return model(input_data.to(device))"
      ],
      "metadata": {
        "id": "eKwS9g1Kf-KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2OJmBUeOf-QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def predict_fn(input_data, model):\n",
        "    device = torch.device(\"cpu\")\n",
        "    model = model.to(device)\n",
        "    input_data = data.to(device)\n",
        "    model.eval()\n",
        "    with torch.jit.optimized_execution(True, {\"target_device\": \"eia:0\"}):\n",
        "        output = model(input_data)"
      ],
      "metadata": {
        "id": "96HgTihif-VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ou5DPNLif-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def predict_fn(input_data, model):\n",
        "    device = torch.device(\"cpu\")\n",
        "    input_data = data.to(device)\n",
        "    # make sure torcheia is imported so that Elastic Inference api call will be invoked\n",
        "    import torcheia\n",
        "    # we need to set the profiling executor for EIA\n",
        "    torch._C._jit_set_profiling_executor(False)\n",
        "    with torch.jit.optimized_execution(True):\n",
        "        output = model.forward(input_data)"
      ],
      "metadata": {
        "id": "VrTfIjhrf-g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2Bn5F7fNf-m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_fn(prediction, content_type, context)"
      ],
      "metadata": {
        "id": "aTwdSciyf-sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kHsPsF1uf-xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker import get_execution_role\n",
        "role = get_execution_role()\n",
        "\n",
        "pytorch_model = PyTorchModel(model_data='s3://my-bucket/my-path/model.tar.gz', role=role,\n",
        "                             entry_point='inference.py')\n",
        "\n",
        "predictor = pytorch_model.deploy(instance_type='ml.c4.xlarge', initial_instance_count=1)"
      ],
      "metadata": {
        "id": "CCNV58zmf-2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Kxd4DtApgK3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_training_job_name = 'MyAwesomePyTorchTrainingJob'\n",
        "pytorch_estimator = PyTorch.attach(my_training_job_name)"
      ],
      "metadata": {
        "id": "fQgBK37pf_BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8NMn2THqf_GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0d8-TxVf_Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HLtdwZKrf_Q6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Xijbcx6f_WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AThRS2k1f_b-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3cCvqkAf_qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FHAugwzSf_w4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Mr0dKYsf_16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rdGb7ga0byg4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QLtQvn1Nb3m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow\n",
        "\n",
        "#### Deploying to TensorFlow Serving Endpoints"
      ],
      "metadata": {
        "id": "so_m2Sn14P65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VYY0StQCcZff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlow\n",
        "\n",
        "estimator = TensorFlow(\n",
        "    entry_point=\"tf-train.py\",\n",
        "    ...,\n",
        "    instance_count=1,\n",
        "    instance_type=\"ml.c4.xlarge\",\n",
        "    framework_version=\"2.2\",\n",
        "    py_version=\"py37\",\n",
        ")\n",
        "\n",
        "estimator.fit(inputs)\n",
        "\n",
        "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")"
      ],
      "metadata": {
        "id": "W_RU9u3-4QAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SnLrIwfScZ_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlowModel\n",
        "\n",
        "model = TensorFlowModel(model_data='s3://mybucket/model.tar.gz', role='MySageMakerRole')\n",
        "\n",
        "predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')"
      ],
      "metadata": {
        "id": "ZPQj38xEcaEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-ju2dq2ZcaZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlowModel\n",
        "\n",
        "model = TensorFlowModel(model_data='s3://mybucket/model.tar.gz', role='MySageMakerRole')\n",
        "\n",
        "predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge', accelerator_type='ml.eia1.medium')"
      ],
      "metadata": {
        "id": "ZNWBrA86cagX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DdTDAZfTcal5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\n",
        "  'instances': [1.0, 2.0, 5.0]\n",
        "}\n",
        "result = predictor.predict(input)"
      ],
      "metadata": {
        "id": "mKOjptWWcaqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Irog5yDtcavx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  'predictions': [3.5, 4.0, 5.5]\n",
        "}"
      ],
      "metadata": {
        "id": "99xi7gTfca1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pJdjXMy4ca6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input matches the Classify and Regress API\n",
        "input = {\n",
        "  'signature_name': 'tensorflow/serving/regress',\n",
        "  'examples': [{'x': 1.0}, {'x': 2.0}]\n",
        "}\n",
        "\n",
        "result = predictor.regress(input)  # or predictor.classify(...)\n",
        "\n",
        "# result contains:\n",
        "{\n",
        "  'results': [3.5, 4.0]\n",
        "}"
      ],
      "metadata": {
        "id": "rUb-mvz-ca-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ibqwug8kcbDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\n",
        "  'instances': [\n",
        "    [1.0, 2.0, 5.0],\n",
        "    [1.0, 2.0, 5.0],\n",
        "    [1.0, 2.0, 5.0]\n",
        "  ]\n",
        "}\n",
        "result = predictor.predict(input)\n",
        "\n",
        "# result contains:\n",
        "{\n",
        "  'predictions': [\n",
        "    [3.5, 4.0, 5.5],\n",
        "    [3.5, 4.0, 5.5],\n",
        "    [3.5, 4.0, 5.5]\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "SiIeL6UCcbP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "phFUEWiucbUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = [\n",
        "  [1.0, 2.0, 5.0],\n",
        "  [1.0, 2.0, 5.0]\n",
        "]\n",
        "result = predictor.predict(input)\n",
        "\n",
        "# result contains:\n",
        "{\n",
        "  'predictions': [\n",
        "    [3.5, 4.0, 5.5],\n",
        "    [3.5, 4.0, 5.5]\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "DZg-QzYfcbY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xaqerqGzcbdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'x' must match name of input tensor in your SavedModel graph\n",
        "# for models with multiple named inputs, just include all the keys in the input dict\n",
        "input = {\n",
        "  'x': [1.0, 2.0, 5.0]\n",
        "}\n",
        "\n",
        "# result contains:\n",
        "{\n",
        "  'predictions': [\n",
        "    [3.5, 4.0, 5.5]\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "_7RqsMezcbiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5GwJfFTCcbmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a Predictor without JSON serialization\n",
        "\n",
        "predictor = Predictor('endpoint-name', serializer=None, content_type='application/jsonlines')\n",
        "\n",
        "input = '''{'x': [1.0, 2.0, 5.0]}\n",
        "{'x': [1.0, 2.0, 5.0]}\n",
        "{'x': [1.0, 2.0, 5.0]}'''\n",
        "\n",
        "result = predictor.predict(input)\n",
        "\n",
        "# result contains:\n",
        "{\n",
        "  'predictions': [\n",
        "    [3.5, 4.0, 5.5],\n",
        "    [3.5, 4.0, 5.5],\n",
        "    [3.5, 4.0, 5.5]\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "wyeY_YBucbz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hu0_4I38cb6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a Predictor with JSON serialization\n",
        "\n",
        "predictor = Predictor('endpoint-name', serializer=sagemaker.serializers.CSVSerializer())\n",
        "\n",
        "# CSV-formatted string input\n",
        "input = '1.0,2.0,5.0\\n1.0,2.0,5.0\\n1.0,2.0,5.0'\n",
        "\n",
        "result = predictor.predict(input)\n",
        "\n",
        "# result contains:\n",
        "{\n",
        "  'predictions': [\n",
        "    [3.5, 4.0, 5.5],\n",
        "    [3.5, 4.0, 5.5],\n",
        "    [3.5, 4.0, 5.5]\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "y1bUiYIucb95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4jqFAC7mccCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlowModel\n",
        "\n",
        "model = Model(entry_point='inference.py',\n",
        "              model_data='s3://mybucket/model.tar.gz',\n",
        "              role='MySageMakerRole')"
      ],
      "metadata": {
        "id": "_3Ckos1jccGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "03Ausm1sccKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def input_handler(data, context):\n",
        "    \"\"\" Pre-process request input before it is sent to TensorFlow Serving REST API\n",
        "    Args:\n",
        "        data (obj): the request data, in format of dict or string\n",
        "        context (Context): an object containing request and configuration details\n",
        "    Returns:\n",
        "        (dict): a JSON-serializable dict that contains request body and headers\n",
        "    \"\"\"\n",
        "    if context.request_content_type == 'application/json':\n",
        "        # pass through json (assumes it's correctly formed)\n",
        "        d = data.read().decode('utf-8')\n",
        "        return d if len(d) else ''\n",
        "\n",
        "    if context.request_content_type == 'text/csv':\n",
        "        # very simple csv handler\n",
        "        return json.dumps({\n",
        "            'instances': [float(x) for x in data.read().decode('utf-8').split(',')]\n",
        "        })\n",
        "\n",
        "    raise ValueError('{{\"error\": \"unsupported content type {}\"}}'.format(\n",
        "        context.request_content_type or \"unknown\"))\n",
        "\n",
        "\n",
        "def output_handler(data, context):\n",
        "    \"\"\"Post-process TensorFlow Serving output before it is returned to the client.\n",
        "    Args:\n",
        "        data (obj): the TensorFlow serving response\n",
        "        context (Context): an object containing request and configuration details\n",
        "    Returns:\n",
        "        (bytes, string): data to return to client, response content type\n",
        "    \"\"\"\n",
        "    if data.status_code != 200:\n",
        "        raise ValueError(data.content.decode('utf-8'))\n",
        "\n",
        "    response_content_type = context.accept_header\n",
        "    prediction = data.content\n",
        "    return prediction, response_content_type"
      ],
      "metadata": {
        "id": "-dm_OWnEcgIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JgaEIgYGdcJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "\n",
        "def handler(data, context):\n",
        "    \"\"\"Handle request.\n",
        "    Args:\n",
        "        data (obj): the request data\n",
        "        context (Context): an object containing request and configuration details\n",
        "    Returns:\n",
        "        (bytes, string): data to return to client, (optional) response content type\n",
        "    \"\"\"\n",
        "    processed_input = _process_input(data, context)\n",
        "    response = requests.post(context.rest_uri, data=processed_input)\n",
        "    return _process_output(response, context)\n",
        "\n",
        "\n",
        "def _process_input(data, context):\n",
        "    if context.request_content_type == 'application/json':\n",
        "        # pass through json (assumes it's correctly formed)\n",
        "        d = data.read().decode('utf-8')\n",
        "        return d if len(d) else ''\n",
        "\n",
        "    if context.request_content_type == 'text/csv':\n",
        "        # very simple csv handler\n",
        "        return json.dumps({\n",
        "            'instances': [float(x) for x in data.read().decode('utf-8').split(',')]\n",
        "        })\n",
        "\n",
        "    raise ValueError('{{\"error\": \"unsupported content type {}\"}}'.format(\n",
        "        context.request_content_type or \"unknown\"))\n",
        "\n",
        "\n",
        "def _process_output(data, context):\n",
        "    if data.status_code != 200:\n",
        "        raise ValueError(data.content.decode('utf-8'))\n",
        "\n",
        "    response_content_type = context.accept_header\n",
        "    prediction = data.content\n",
        "    return prediction, response_content_type"
      ],
      "metadata": {
        "id": "xrMs3Gn0dcNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WAvQ7ToddcTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlowModel\n",
        "\n",
        "model = Model(entry_point='inference.py',\n",
        "              source_dir='source/directory',\n",
        "              model_data='s3://mybucket/model.tar.gz',\n",
        "              role='MySageMakerRole')"
      ],
      "metadata": {
        "id": "FS37IjOedcXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zn07MqMBdccz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlowModel\n",
        "\n",
        "model = Model(entry_point='inference.py',\n",
        "              dependencies=['/path/to/folder/named/lib'],\n",
        "              model_data='s3://mybucket/model.tar.gz',\n",
        "              role='MySageMakerRole')"
      ],
      "metadata": {
        "id": "k-w_fa4Rdchd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rqYFz15Hdcmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws s3 cp s3://mybucket/models/model1/model.tar.gz model1.tar.gz\n",
        "aws s3 cp s3://mybucket/models/model2/model.tar.gz model2.tar.gz\n",
        "mkdir -p multi/model1\n",
        "mkdir -p multi/model2\n",
        "\n",
        "tar xvf model1.tar.gz -C ./multi/model1\n",
        "tar xvf model2.tar.gz -C ./multi/model2"
      ],
      "metadata": {
        "id": "hThwX1ROdcrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UpHtHPbidcwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mv multi/model1/export/Servo/* multi/model1/\n",
        "mv multi/model2/export/Servo/* multi/model2/\n",
        "rm -fr multi/model1/export\n",
        "rm -fr multi/model2/export"
      ],
      "metadata": {
        "id": "WduSktHWdc1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3sS2d_vEdc6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tar -C \"$PWD/multi/\" -czvf multi.tar.gz multi/"
      ],
      "metadata": {
        "id": "rme5hMgWdc_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vg7Cj5EOddD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aws s3 cp multi.tar.gz s3://mybucket/models/multi.tar.gz"
      ],
      "metadata": {
        "id": "Lf5P7QJdddIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "i4hmC2FTddNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.tensorflow import TensorFlowModel, TensorFlowPredictor\n",
        "\n",
        "# change this to the name or ARN of your SageMaker execution role\n",
        "role = 'SageMakerRole'\n",
        "\n",
        "model_data = 's3://mybucket/models/multi.tar.gz'\n",
        "\n",
        "# For multi-model endpoints, you should set the default model name in\n",
        "# an environment variable. If it isn't set, the endpoint will work,\n",
        "# but the model it will select as default is unpredictable.\n",
        "env = {\n",
        "  'SAGEMAKER_TFS_DEFAULT_MODEL_NAME': 'model1'\n",
        "}\n",
        "\n",
        "model = Model(model_data=model_data, role=role, framework_version='1.11', env=env)\n",
        "predictor = model.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge')"
      ],
      "metadata": {
        "id": "Odfaq43RddSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sAkDXBQbddXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... continuing from the previous example\n",
        "\n",
        "# get the endpoint name from the default predictor\n",
        "endpoint = predictor.endpoint_name\n",
        "\n",
        "# get a predictor for 'model2'\n",
        "model2_predictor = Predictor(endpoint, model_name='model2')\n",
        "\n",
        "# note: that will for actual SageMaker endpoints, but if you are using\n",
        "# local mode you need to create the new Predictor this way:\n",
        "#\n",
        "# model2_predictor = Predictor(endpoint, model_name='model2'\n",
        "#                              sagemaker_session=predictor.sagemaker_session)\n",
        "\n",
        "\n",
        "# result is prediction from 'model2'\n",
        "result = model2_predictor.predict(...)"
      ],
      "metadata": {
        "id": "nInNiFBoddby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7wtLg3Z1ddgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow Serving REST API - predict request\n",
        "aws sagemaker-runtime invoke-endpoint \\\n",
        "    --endpoint-name my-endpoint \\\n",
        "    --content-type 'application/json' \\\n",
        "    --body '{\"instances\": [1.0, 2.0, 5.0]}' \\\n",
        "    >(cat) 1>/dev/null\n",
        "\n",
        "# Predict request for specific model name\n",
        "aws sagemaker-runtime invoke-endpoint \\\n",
        "    --endpoint-name my-endpoint \\\n",
        "    --content-type 'application/json' \\\n",
        "    --body '{\"instances\": [1.0, 2.0, 5.0]}' \\\n",
        "    --custom-attributes 'tfs-model-name=other_model' \\\n",
        "    >(cat) 1>/dev/null\n",
        "\n",
        "# TensorFlow Serving REST API - regress request\n",
        "aws sagemaker-runtime invoke-endpoint \\\n",
        "    --endpoint-name my-endpoint \\\n",
        "    --content-type 'application/json' \\\n",
        "    --body '{\"signature_name\": \"tensorflow/serving/regress\",\"examples\": [{\"x\": 1.0}]}' \\\n",
        "    --custom-attributes 'tfs-method=regress' \\\n",
        "    >(cat) 1>/dev/null\n",
        "\n",
        "# Simple json request (2 instances)\n",
        "aws sagemaker-runtime invoke-endpoint \\\n",
        "    --endpoint-name my-endpoint \\\n",
        "    --content-type 'application/json' \\\n",
        "    --body '[[1.0, 2.0, 5.0],[2.0, 3.0, 4.0]]' \\\n",
        "    >(cat) 1>/dev/null\n",
        "\n",
        "# CSV request (2 rows)\n",
        "aws sagemaker-runtime invoke-endpoint \\\n",
        "    --endpoint-name my-endpoint \\\n",
        "    --content-type 'text/csv' \\\n",
        "    --body \"1.0,2.0,5.0\"$'\\n'\"2.0,3.0,4.0\" \\\n",
        "    >(cat) 1>/dev/null\n",
        "\n",
        "# Line delimited JSON from an input file\n",
        "aws sagemaker-runtime invoke-endpoint \\\n",
        "    --endpoint-name my-endpoint \\\n",
        "    --content-type 'application/jsons' \\\n",
        "    --body \"$(cat input.jsons)\" \\\n",
        "    results.json"
      ],
      "metadata": {
        "id": "2CB2lBdIddlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "ktbkIiilddp7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KR3p9qjPddum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Em8IbEL0ddzC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MppDaCPmdd4O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}